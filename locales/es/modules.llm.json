{
  "$schema": "../../schema/locale.schema.json",
  "locale": "es",
  "category": "llm",
  "version": "1.0.0",
  "translations": {
    "modules.llm.agent.description": "Agente de IA autonomo con conexiones multi-puerto (modelo, memoria, herramientas)",
    "modules.llm.agent.label": "Agente de IA",
    "modules.llm.agent.output.ok.description": "Si el agente completo exitosamente",
    "modules.llm.agent.output.result.description": "Si el agente completo exitosamente",
    "modules.llm.agent.output.steps.description": "Si el agente completo exitosamente",
    "modules.llm.agent.output.tokens_used.description": "Lista de pasos que tomo el agente",
    "modules.llm.agent.output.tool_calls.description": "El resultado final del agente",
    "modules.llm.agent.params.context": "Herramientas disponibles",
    "modules.llm.agent.params.context.description": "Lista de IDs de modulo (alternativa a conectar nodos de herramientas)",
    "modules.llm.agent.params.join_separator": "Separador de union",
    "modules.llm.agent.params.join_separator.description": "Separador para unir elementos de array",
    "modules.llm.agent.params.join_strategy": "Estrategia de union de array",
    "modules.llm.agent.params.join_strategy.description": "Como manejar entradas de array",
    "modules.llm.agent.params.max_input_size": "Tamano maximo de entrada",
    "modules.llm.agent.params.max_input_size.description": "Maximo de caracteres para prompt (previene desbordamiento)",
    "modules.llm.agent.params.max_iterations": "Contexto",
    "modules.llm.agent.params.max_iterations.description": "Datos de contexto adicionales para el agente",
    "modules.llm.agent.params.prompt_path": "Ruta del prompt",
    "modules.llm.agent.params.prompt_path.description": "Ruta para extraer prompt de entrada (ej., {{input.message}})",
    "modules.llm.agent.params.prompt_source": "Fuente del prompt",
    "modules.llm.agent.params.prompt_source.description": "De donde obtener el prompt de la tarea",
    "modules.llm.agent.params.system_prompt": "Prompt del sistema",
    "modules.llm.agent.params.system_prompt.description": "Instrucciones para el comportamiento del agente",
    "modules.llm.agent.params.task": "Tarea",
    "modules.llm.agent.params.task.description": "La tarea para que el agente complete. Usa {{input}} para referenciar datos anteriores.",
    "modules.llm.agent.params.tools": "Herramientas disponibles",
    "modules.llm.agent.params.tools.description": "Lista de IDs de modulo (alternativa a conectar nodos de herramientas)",
    "modules.llm.agent.params.tools.options.array.filter": "Array.Filter",
    "modules.llm.agent.params.tools.options.data.csv_parse": "Data.Csv Parse",
    "modules.llm.agent.params.tools.options.file.read": "File.Read",
    "modules.llm.agent.ports.input": "Entrada",
    "modules.llm.agent.ports.memory": "Modelo",
    "modules.llm.agent.ports.model": "Entrada",
    "modules.llm.agent.ports.output": "Herramientas",
    "modules.llm.agent.ports.tools": "Memoria",
    "modules.llm.chat.description": "Interactuar con APIs de LLM para operaciones inteligentes",
    "modules.llm.chat.label": "Chat LLM",
    "modules.llm.chat.output.finish_reason.description": "Modelo usado",
    "modules.llm.chat.output.model.description": "El texto de respuesta del LLM",
    "modules.llm.chat.output.ok.description": "Si la solicitud tuvo exito",
    "modules.llm.chat.output.parsed.description": "Si la solicitud tuvo exito",
    "modules.llm.chat.output.response.description": "Si la solicitud tuvo exito",
    "modules.llm.chat.output.tokens_used.description": "Respuesta parseada (si se solicito formato JSON)",
    "modules.llm.code_fix.description": "Generar automaticamente correcciones de codigo basadas en problemas",
    "modules.llm.code_fix.label": "Correccion de codigo con IA",
    "modules.llm.code_fix.output.applied.description": "Si la operacion tuvo exito",
    "modules.llm.code_fix.output.failed.description": "Lista de correcciones generadas",
    "modules.llm.code_fix.output.fixes.description": "Si la operacion tuvo exito",
    "modules.llm.code_fix.output.ok.description": "Si la operacion tuvo exito",
    "modules.llm.code_fix.output.summary.description": "Lista de correcciones aplicadas (si fix_mode es apply)",
    "modules.llm.code_fix.params.fixes": "Correcciones",
    "modules.llm.code_fix.params.source_files": "Archivos Fuente"
  }
}
