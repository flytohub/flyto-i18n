{
  "$schema": "../../schema/locale.schema.json",
  "locale": "pt-BR",
  "category": "llm",
  "version": "1.0.0",
  "translations": {
    "modules.llm.agent.description": "Agente de IA autonomo com conexoes multi-porta (modelo, memoria, ferramentas)",
    "modules.llm.agent.label": "Agente de IA",
    "modules.llm.agent.output.ok.description": "Se o agente completou com sucesso",
    "modules.llm.agent.output.result.description": "Se o agente completou com sucesso",
    "modules.llm.agent.output.steps.description": "Se o agente completou com sucesso",
    "modules.llm.agent.output.tokens_used.description": "Lista de passos que o agente executou",
    "modules.llm.agent.output.tool_calls.description": "O resultado final do agente",
    "modules.llm.agent.params.context": "Ferramentas Disponiveis",
    "modules.llm.agent.params.context.description": "Lista de IDs de modulos (alternativa a conectar nos de ferramentas)",
    "modules.llm.agent.params.join_separator": "Separador de Juncao",
    "modules.llm.agent.params.join_separator.description": "Separador para juntar itens de array",
    "modules.llm.agent.params.join_strategy": "Estrategia de Juncao de Array",
    "modules.llm.agent.params.join_strategy.description": "Como lidar com entradas de array",
    "modules.llm.agent.params.max_input_size": "Tamanho Max de Entrada",
    "modules.llm.agent.params.max_input_size.description": "Maximo de caracteres para prompt (previne overflow)",
    "modules.llm.agent.params.max_iterations": "Contexto",
    "modules.llm.agent.params.max_iterations.description": "Dados de contexto adicionais para o agente",
    "modules.llm.agent.params.prompt_path": "Caminho do Prompt",
    "modules.llm.agent.params.prompt_path.description": "Caminho para extrair prompt da entrada (ex: {{input.message}})",
    "modules.llm.agent.params.prompt_source": "Fonte do Prompt",
    "modules.llm.agent.params.prompt_source.description": "De onde obter o prompt da tarefa",
    "modules.llm.agent.params.system_prompt": "Prompt do Sistema",
    "modules.llm.agent.params.system_prompt.description": "Instrucoes para o comportamento do agente",
    "modules.llm.agent.params.task": "Tarefa",
    "modules.llm.agent.params.task.description": "A tarefa para o agente completar. Use {{input}} para referenciar dados upstream.",
    "modules.llm.agent.params.tools": "Ferramentas Disponiveis",
    "modules.llm.agent.params.tools.description": "Lista de IDs de modulos (alternativa a conectar nos de ferramentas)",
    "modules.llm.agent.params.tools.options.array.filter": "Array.Filtrar",
    "modules.llm.agent.params.tools.options.data.csv_parse": "Dados.Analisar CSV",
    "modules.llm.agent.params.tools.options.file.read": "Arquivo.Ler",
    "modules.llm.agent.ports.input": "Entrada",
    "modules.llm.agent.ports.memory": "Modelo",
    "modules.llm.agent.ports.model": "Entrada",
    "modules.llm.agent.ports.output": "Ferramentas",
    "modules.llm.agent.ports.tools": "Memoria",
    "modules.llm.chat.description": "Interagir com APIs de LLM para operacoes inteligentes",
    "modules.llm.chat.label": "Chat LLM",
    "modules.llm.chat.output.finish_reason.description": "Modelo usado",
    "modules.llm.chat.output.model.description": "O texto de resposta do LLM",
    "modules.llm.chat.output.ok.description": "Se a requisicao teve sucesso",
    "modules.llm.chat.output.parsed.description": "Se a requisicao teve sucesso",
    "modules.llm.chat.output.response.description": "Se a requisicao teve sucesso",
    "modules.llm.chat.output.tokens_used.description": "Resposta parseada (se formato JSON solicitado)",
    "modules.llm.code_fix.description": "Gerar automaticamente correcoes de codigo baseadas em problemas",
    "modules.llm.code_fix.label": "Correcao de Codigo IA",
    "modules.llm.code_fix.output.applied.description": "Se a operacao teve sucesso",
    "modules.llm.code_fix.output.failed.description": "Lista de correcoes geradas",
    "modules.llm.code_fix.output.fixes.description": "Se a operacao teve sucesso",
    "modules.llm.code_fix.output.ok.description": "Se a operacao teve sucesso",
    "modules.llm.code_fix.output.summary.description": "Lista de correcoes aplicadas (se fix_mode for apply)",
    "modules.llm.code_fix.params.fixes": "Correções",
    "modules.llm.code_fix.params.source_files": "Arquivos Fonte"
  }
}
