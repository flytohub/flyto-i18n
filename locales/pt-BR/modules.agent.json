{
  "$schema": "../../schema/locale.schema.json",
  "locale": "pt-BR",
  "category": "agent",
  "version": "1.0.0",
  "translations": {
    "modules.agent.autonomous.description": "Agente de IA autodirigido com memoria e comportamento orientado a objetivos",
    "modules.agent.autonomous.label": "Agente Autonomo",
    "modules.agent.autonomous.output.goal_achieved.description": "Passos de raciocinio do agente",
    "modules.agent.autonomous.output.iterations.description": "O resultado da operacao",
    "modules.agent.autonomous.output.result.description": "Nivel de criatividade (0-2)",
    "modules.agent.autonomous.output.thoughts.description": "O resultado da operacao",
    "modules.agent.autonomous.params.context.description": "O objetivo para o agente alcancar",
    "modules.agent.autonomous.params.context.label": "Objetivo",
    "modules.agent.autonomous.params.goal.description": "O objetivo para o agente alcancar",
    "modules.agent.autonomous.params.goal.label": "Objetivo",
    "modules.agent.autonomous.params.llm_provider.description": "Maximo de passos de raciocinio",
    "modules.agent.autonomous.params.llm_provider.label": "Max Iteracoes",
    "modules.agent.autonomous.params.max_iterations.description": "Contexto adicional ou restricoes",
    "modules.agent.autonomous.params.max_iterations.label": "Contexto",
    "modules.agent.autonomous.params.model.description": "Nome do modelo (ex: gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.model.label": "OpenAI (Cloud)",
    "modules.agent.autonomous.params.ollama_url.description": "Nome do modelo (ex: gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.ollama_url.label": "Modelo",
    "modules.agent.autonomous.params.temperature.description": "URL do servidor Ollama (apenas para provedor ollama)",
    "modules.agent.autonomous.params.temperature.label": "URL Ollama",
    "modules.agent.chain.description": "Cadeia de processamento de IA sequencial com multiplos passos",
    "modules.agent.chain.label": "Agente de Cadeia",
    "modules.agent.chain.output.intermediate_results.description": "O resultado da operacao",
    "modules.agent.chain.output.result.description": "Nivel de criatividade (0-2)",
    "modules.agent.chain.output.steps_completed.description": "O resultado da operacao",
    "modules.agent.chain.params.chain_steps": "Chain Steps",
    "modules.agent.chain.params.chain_steps.description": "Entrada inicial para a cadeia",
    "modules.agent.chain.params.chain_steps.label": "Entrada",
    "modules.agent.chain.params.chain_steps.options.Analyze what might cause this issue: {input}": "Analyze What Might Cause This Issue: {Input}",
    "modules.agent.chain.params.chain_steps.options.Create an action plan from: {previous}": "Create An Action Plan From: {Previous}",
    "modules.agent.chain.params.chain_steps.options.Suggest 3 solutions based on: {previous}": "Suggest 3 Solutions Based On: {Previous}",
    "modules.agent.chain.params.input.description": "Entrada inicial para a cadeia",
    "modules.agent.chain.params.input.label": "Entrada",
    "modules.agent.chain.params.llm_provider.description": "Array de passos de processamento (cada um e um template de prompt)",
    "modules.agent.chain.params.llm_provider.label": "Passos da Cadeia",
    "modules.agent.chain.params.model.description": "Nome do modelo (ex: gpt-4, llama2, mistral)",
    "modules.agent.chain.params.model.label": "OpenAI (Cloud)",
    "modules.agent.chain.params.ollama_url.description": "Nome do modelo (ex: gpt-4, llama2, mistral)",
    "modules.agent.chain.params.ollama_url.label": "Modelo",
    "modules.agent.chain.params.temperature.description": "URL do servidor Ollama (apenas para provedor ollama)",
    "modules.agent.chain.params.temperature.label": "URL Ollama"
  }
}
