{
  "$schema": "../../schema/locale.schema.json",
  "locale": "fr",
  "category": "agent",
  "version": "1.0.0",
  "translations": {
    "modules.agent.autonomous.description": "Agent IA autodirige avec memoire et comportement oriente objectif",
    "modules.agent.autonomous.label": "Agent autonome",
    "modules.agent.autonomous.output.goal_achieved.description": "Etapes de raisonnement de l'agent",
    "modules.agent.autonomous.output.iterations.description": "Resultat de l'operation",
    "modules.agent.autonomous.output.result.description": "Niveau de creativite (0-2)",
    "modules.agent.autonomous.output.thoughts.description": "Resultat de l'operation",
    "modules.agent.autonomous.params.context.description": "L'objectif a atteindre par l'agent",
    "modules.agent.autonomous.params.context.label": "Objectif",
    "modules.agent.autonomous.params.goal.description": "L'objectif a atteindre par l'agent",
    "modules.agent.autonomous.params.goal.label": "Objectif",
    "modules.agent.autonomous.params.llm_provider.description": "Etapes de raisonnement maximum",
    "modules.agent.autonomous.params.llm_provider.label": "Iterations max",
    "modules.agent.autonomous.params.max_iterations.description": "Contexte ou contraintes supplementaires",
    "modules.agent.autonomous.params.max_iterations.label": "Contexte",
    "modules.agent.autonomous.params.model.description": "Nom du modele (ex: gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.model.label": "OpenAI (Cloud)",
    "modules.agent.autonomous.params.ollama_url.description": "Nom du modele (ex: gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.ollama_url.label": "Modele",
    "modules.agent.autonomous.params.temperature.description": "URL du serveur Ollama (uniquement pour le fournisseur ollama)",
    "modules.agent.autonomous.params.temperature.label": "URL Ollama",
    "modules.agent.chain.description": "Chaine de traitement IA sequentielle avec plusieurs etapes",
    "modules.agent.chain.label": "Agent en chaine",
    "modules.agent.chain.output.intermediate_results.description": "Resultat de l'operation",
    "modules.agent.chain.output.result.description": "Niveau de creativite (0-2)",
    "modules.agent.chain.output.steps_completed.description": "Resultat de l'operation",
    "modules.agent.chain.params.chain_steps": "Chain Steps",
    "modules.agent.chain.params.chain_steps.description": "Entree initiale pour la chaine",
    "modules.agent.chain.params.chain_steps.label": "Entree",
    "modules.agent.chain.params.chain_steps.options.Analyze what might cause this issue: {input}": "Analyze What Might Cause This Issue: {Input}",
    "modules.agent.chain.params.chain_steps.options.Create an action plan from: {previous}": "Create An Action Plan From: {Previous}",
    "modules.agent.chain.params.chain_steps.options.Suggest 3 solutions based on: {previous}": "Suggest 3 Solutions Based On: {Previous}",
    "modules.agent.chain.params.input.description": "Entree initiale pour la chaine",
    "modules.agent.chain.params.input.label": "Entree",
    "modules.agent.chain.params.llm_provider.description": "Tableau d'etapes de traitement (chacune est un modele de prompt)",
    "modules.agent.chain.params.llm_provider.label": "Etapes de la chaine",
    "modules.agent.chain.params.model.description": "Nom du modele (ex: gpt-4, llama2, mistral)",
    "modules.agent.chain.params.model.label": "OpenAI (Cloud)",
    "modules.agent.chain.params.ollama_url.description": "Nom du modele (ex: gpt-4, llama2, mistral)",
    "modules.agent.chain.params.ollama_url.label": "Modele",
    "modules.agent.chain.params.temperature.description": "URL du serveur Ollama (uniquement pour le fournisseur ollama)",
    "modules.agent.chain.params.temperature.label": "URL Ollama"
  }
}
