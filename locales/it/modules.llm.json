{
  "$schema": "../../schema/locale.schema.json",
  "locale": "it",
  "category": "llm",
  "version": "1.0.0",
  "translations": {
    "modules.llm.agent.description": "Agente AI autonomo con connessioni multi-porta (modello, memoria, strumenti)",
    "modules.llm.agent.label": "Agente AI",
    "modules.llm.agent.output.ok.description": "Se l'agente ha completato con successo",
    "modules.llm.agent.output.result.description": "Se l'agente ha completato con successo",
    "modules.llm.agent.output.steps.description": "Se l'agente ha completato con successo",
    "modules.llm.agent.output.tokens_used.description": "Lista dei passaggi eseguiti dall'agente",
    "modules.llm.agent.output.tool_calls.description": "Il risultato finale dell'agente",
    "modules.llm.agent.params.context": "Strumenti Disponibili",
    "modules.llm.agent.params.context.description": "Lista di ID modulo (alternativa alla connessione di nodi strumento)",
    "modules.llm.agent.params.join_separator": "Separatore Unione",
    "modules.llm.agent.params.join_separator.description": "Separatore per unire elementi array",
    "modules.llm.agent.params.join_strategy": "Strategia Unione Array",
    "modules.llm.agent.params.join_strategy.description": "Come gestire gli input array",
    "modules.llm.agent.params.max_input_size": "Dimensione Max Input",
    "modules.llm.agent.params.max_input_size.description": "Caratteri massimi per prompt (previene overflow)",
    "modules.llm.agent.params.max_iterations": "Contesto",
    "modules.llm.agent.params.max_iterations.description": "Dati di contesto aggiuntivi per l'agente",
    "modules.llm.agent.params.prompt_path": "Percorso Prompt",
    "modules.llm.agent.params.prompt_path.description": "Percorso per estrarre prompt dall'input (es. {{input.message}})",
    "modules.llm.agent.params.prompt_source": "Sorgente Prompt",
    "modules.llm.agent.params.prompt_source.description": "Da dove ottenere il prompt del task",
    "modules.llm.agent.params.system_prompt": "Prompt di Sistema",
    "modules.llm.agent.params.system_prompt.description": "Istruzioni per il comportamento dell'agente",
    "modules.llm.agent.params.task": "Task",
    "modules.llm.agent.params.task.description": "Il task da completare per l'agente. Usa {{input}} per riferimento a dati upstream.",
    "modules.llm.agent.params.tools": "Strumenti Disponibili",
    "modules.llm.agent.params.tools.description": "Lista di ID modulo (alternativa alla connessione di nodi strumento)",
    "modules.llm.agent.ports.input": "Input",
    "modules.llm.agent.ports.memory": "Modello",
    "modules.llm.agent.ports.model": "Input",
    "modules.llm.agent.ports.output": "Strumenti",
    "modules.llm.agent.ports.tools": "Memoria",
    "modules.llm.chat.description": "Interagisci con API LLM per operazioni intelligenti",
    "modules.llm.chat.label": "Chat LLM",
    "modules.llm.chat.output.finish_reason.description": "Modello usato",
    "modules.llm.chat.output.model.description": "Il testo di risposta LLM",
    "modules.llm.chat.output.ok.description": "Se la richiesta e riuscita",
    "modules.llm.chat.output.parsed.description": "Se la richiesta e riuscita",
    "modules.llm.chat.output.response.description": "Se la richiesta e riuscita",
    "modules.llm.chat.output.tokens_used.description": "Risposta parsata (se richiesto formato JSON)",
    "modules.llm.code_fix.description": "Genera automaticamente correzioni di codice basate sui problemi",
    "modules.llm.code_fix.label": "Correzione Codice AI",
    "modules.llm.code_fix.output.applied.description": "Se l'operazione e riuscita",
    "modules.llm.code_fix.output.failed.description": "Lista delle correzioni generate",
    "modules.llm.code_fix.output.fixes.description": "Se l'operazione e riuscita",
    "modules.llm.code_fix.output.ok.description": "Se l'operazione e riuscita",
    "modules.llm.code_fix.output.summary.description": "Lista delle correzioni applicate (se fix_mode e apply)"
  }
}
