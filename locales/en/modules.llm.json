{
  "$schema": "../../schema/locale.schema.json",
  "locale": "en",
  "category": "llm",
  "version": "1.0.0",
  "translations": {
    "modules.llm.agent.description": "Autonomous AI agent with multi-port connections (model, memory, tools)",
    "modules.llm.agent.label": "AI Agent",
    "modules.llm.agent.output.ok.description": "Whether the agent completed successfully",
    "modules.llm.agent.output.result.description": "Whether the agent completed successfully",
    "modules.llm.agent.output.steps.description": "Whether the agent completed successfully",
    "modules.llm.agent.output.tokens_used.description": "List of steps the agent took",
    "modules.llm.agent.output.tool_calls.description": "The final result from the agent",
    "modules.llm.agent.params.context": "Available Tools",
    "modules.llm.agent.params.context.description": "List of module IDs (alternative to connecting tool nodes)",
    "modules.llm.agent.params.join_separator": "Join Separator",
    "modules.llm.agent.params.join_separator.description": "Separator for joining array items",
    "modules.llm.agent.params.join_strategy": "Array Join Strategy",
    "modules.llm.agent.params.join_strategy.description": "How to handle array inputs",
    "modules.llm.agent.params.max_input_size": "Max Input Size",
    "modules.llm.agent.params.max_input_size.description": "Maximum characters for prompt (prevents overflow)",
    "modules.llm.agent.params.max_iterations": "Context",
    "modules.llm.agent.params.max_iterations.description": "Additional context data for the agent",
    "modules.llm.agent.params.prompt_path": "Prompt Path",
    "modules.llm.agent.params.prompt_path.description": "Path to extract prompt from input (e.g., {{input.message}})",
    "modules.llm.agent.params.prompt_source": "Prompt Source",
    "modules.llm.agent.params.prompt_source.description": "Where to get the task prompt from",
    "modules.llm.agent.params.system_prompt": "System Prompt",
    "modules.llm.agent.params.system_prompt.description": "Instructions for the agent behavior",
    "modules.llm.agent.params.task": "Task",
    "modules.llm.agent.params.task.description": "The task for the agent to complete. Use {{input}} to reference upstream data.",
    "modules.llm.agent.params.tools": "Available Tools",
    "modules.llm.agent.params.tools.description": "List of module IDs (alternative to connecting tool nodes)",
    "modules.llm.agent.ports.input": "Input",
    "modules.llm.agent.ports.memory": "Model",
    "modules.llm.agent.ports.model": "Input",
    "modules.llm.agent.ports.output": "Tools",
    "modules.llm.agent.ports.tools": "Memory",
    "modules.llm.chat.description": "Interact with LLM APIs for intelligent operations",
    "modules.llm.chat.label": "LLM Chat",
    "modules.llm.chat.output.finish_reason.description": "Model used",
    "modules.llm.chat.output.model.description": "The LLM response text",
    "modules.llm.chat.output.ok.description": "Whether the request succeeded",
    "modules.llm.chat.output.parsed.description": "Whether the request succeeded",
    "modules.llm.chat.output.response.description": "Whether the request succeeded",
    "modules.llm.chat.output.tokens_used.description": "Parsed response (if JSON format requested)",
    "modules.llm.code_fix.description": "Automatically generate code fixes based on issues",
    "modules.llm.code_fix.label": "AI Code Fix",
    "modules.llm.code_fix.output.applied.description": "Whether operation succeeded",
    "modules.llm.code_fix.output.failed.description": "List of generated fixes",
    "modules.llm.code_fix.output.fixes.description": "Whether operation succeeded",
    "modules.llm.code_fix.output.ok.description": "Whether operation succeeded",
    "modules.llm.code_fix.output.summary.description": "List of applied fixes (if fix_mode is apply)"
  }
}