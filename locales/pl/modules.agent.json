{
  "$schema": "../../schema/locale.schema.json",
  "locale": "pl",
  "category": "agent",
  "version": "1.0.0",
  "translations": {
    "modules.agent.autonomous.description": "Samodzielny agent AI z pamiecia i zachowaniem zorientowanym na cel",
    "modules.agent.autonomous.label": "Agent autonomiczny",
    "modules.agent.autonomous.output.goal_achieved.description": "Kroki rozumowania agenta",
    "modules.agent.autonomous.output.iterations.description": "Wynik operacji",
    "modules.agent.autonomous.output.result.description": "Poziom kreatywnosci (0-2)",
    "modules.agent.autonomous.output.thoughts.description": "Wynik operacji",
    "modules.agent.autonomous.params.context.description": "Cel do osiagniecia przez agenta",
    "modules.agent.autonomous.params.context.label": "Cel",
    "modules.agent.autonomous.params.goal.description": "Cel do osiagniecia przez agenta",
    "modules.agent.autonomous.params.goal.label": "Cel",
    "modules.agent.autonomous.params.llm_provider.description": "Maksymalna liczba krokow rozumowania",
    "modules.agent.autonomous.params.llm_provider.label": "Maks. iteracji",
    "modules.agent.autonomous.params.max_iterations.description": "Dodatkowy kontekst lub ograniczenia",
    "modules.agent.autonomous.params.max_iterations.label": "Kontekst",
    "modules.agent.autonomous.params.model.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.model.label": "OpenAI (chmura)",
    "modules.agent.autonomous.params.ollama_url.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.ollama_url.label": "Model",
    "modules.agent.autonomous.params.temperature.description": "URL serwera Ollama (tylko dla dostawcy ollama)",
    "modules.agent.autonomous.params.temperature.label": "URL Ollama",
    "modules.agent.chain.description": "Sekwencyjny lancuch przetwarzania AI z wieloma krokami",
    "modules.agent.chain.label": "Agent lancuchowy",
    "modules.agent.chain.output.intermediate_results.description": "Wynik operacji",
    "modules.agent.chain.output.result.description": "Poziom kreatywnosci (0-2)",
    "modules.agent.chain.output.steps_completed.description": "Wynik operacji",
    "modules.agent.chain.params.chain_steps.description": "Poczatkowe dane wejsciowe dla lancucha",
    "modules.agent.chain.params.chain_steps.label": "Wejscie",
    "modules.agent.chain.params.input.description": "Poczatkowe dane wejsciowe dla lancucha",
    "modules.agent.chain.params.input.label": "Wejscie",
    "modules.agent.chain.params.llm_provider.description": "Tablica krokow przetwarzania (kazdy jest szablonem promptu)",
    "modules.agent.chain.params.llm_provider.label": "Kroki lancucha",
    "modules.agent.chain.params.model.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.chain.params.model.label": "OpenAI (chmura)",
    "modules.agent.chain.params.ollama_url.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.chain.params.ollama_url.label": "Model",
    "modules.agent.chain.params.temperature.description": "URL serwera Ollama (tylko dla dostawcy ollama)",
    "modules.agent.chain.params.temperature.label": "URL Ollama"
  }
}
