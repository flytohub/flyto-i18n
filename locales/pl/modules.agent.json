{
  "$schema": "../../schema/locale.schema.json",
  "locale": "pl",
  "category": "agent",
  "version": "1.0.0",
  "translations": {
    "modules.agent.autonomous.description": "Samodzielny agent AI z pamiecia i zachowaniem zorientowanym na cel",
    "modules.agent.autonomous.label": "Agent autonomiczny",
    "modules.agent.autonomous.output.goal_achieved.description": "Kroki rozumowania agenta",
    "modules.agent.autonomous.output.iterations.description": "Wynik operacji",
    "modules.agent.autonomous.output.result.description": "Poziom kreatywnosci (0-2)",
    "modules.agent.autonomous.output.thoughts.description": "Wynik operacji",
    "modules.agent.autonomous.params.context.description": "Cel do osiagniecia przez agenta",
    "modules.agent.autonomous.params.context.label": "Cel",
    "modules.agent.autonomous.params.goal.description": "Cel do osiagniecia przez agenta",
    "modules.agent.autonomous.params.goal.label": "Cel",
    "modules.agent.autonomous.params.llm_provider.description": "Maksymalna liczba krokow rozumowania",
    "modules.agent.autonomous.params.llm_provider.label": "Maks. iteracji",
    "modules.agent.autonomous.params.max_iterations.description": "Dodatkowy kontekst lub ograniczenia",
    "modules.agent.autonomous.params.max_iterations.label": "Kontekst",
    "modules.agent.autonomous.params.model.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.model.label": "OpenAI (chmura)",
    "modules.agent.autonomous.params.ollama_url.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.autonomous.params.ollama_url.label": "Model",
    "modules.agent.autonomous.params.temperature.description": "URL serwera Ollama (tylko dla dostawcy ollama)",
    "modules.agent.autonomous.params.temperature.label": "URL Ollama",
    "modules.agent.chain.description": "Sekwencyjny lancuch przetwarzania AI z wieloma krokami",
    "modules.agent.chain.label": "Agent lancuchowy",
    "modules.agent.chain.output.intermediate_results.description": "Wynik operacji",
    "modules.agent.chain.output.result.description": "Poziom kreatywnosci (0-2)",
    "modules.agent.chain.output.steps_completed.description": "Wynik operacji",
    "modules.agent.chain.params.chain_steps": "Chain Steps",
    "modules.agent.chain.params.chain_steps.description": "Poczatkowe dane wejsciowe dla lancucha",
    "modules.agent.chain.params.chain_steps.label": "Wejscie",
    "modules.agent.chain.params.chain_steps.options.Analyze what might cause this issue: {input}": "Analyze What Might Cause This Issue: {Input}",
    "modules.agent.chain.params.chain_steps.options.Create an action plan from: {previous}": "Create An Action Plan From: {Previous}",
    "modules.agent.chain.params.chain_steps.options.Suggest 3 solutions based on: {previous}": "Suggest 3 Solutions Based On: {Previous}",
    "modules.agent.chain.params.input.description": "Poczatkowe dane wejsciowe dla lancucha",
    "modules.agent.chain.params.input.label": "Wejscie",
    "modules.agent.chain.params.llm_provider.description": "Tablica krokow przetwarzania (kazdy jest szablonem promptu)",
    "modules.agent.chain.params.llm_provider.label": "Kroki lancucha",
    "modules.agent.chain.params.model.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.chain.params.model.label": "OpenAI (chmura)",
    "modules.agent.chain.params.ollama_url.description": "Nazwa modelu (np. gpt-4, llama2, mistral)",
    "modules.agent.chain.params.ollama_url.label": "Model",
    "modules.agent.chain.params.temperature.description": "URL serwera Ollama (tylko dla dostawcy ollama)",
    "modules.agent.chain.params.temperature.label": "URL Ollama",
    "modules.agent.tool_use.description": "Agent AI, który może korzystać z narzędzi/funkcji",
    "modules.agent.tool_use.label": "Agent Użycia Narzędzi",
    "modules.agent.tool_use.output.iterations.description": "Liczba ukończonych iteracji",
    "modules.agent.tool_use.output.model.description": "Użyty model",
    "modules.agent.tool_use.output.result.description": "Ostateczna odpowiedź agenta",
    "modules.agent.tool_use.output.tool_calls.description": "Wszystkie wywołania narzędzi wykonane podczas działania",
    "modules.agent.tool_use.params.api_key.description": "Klucz API (domyślnie zmienna środowiskowa)",
    "modules.agent.tool_use.params.api_key.label": "Klucz API",
    "modules.agent.tool_use.params.max_iterations.description": "Maksymalna liczba rund wywołań narzędzi",
    "modules.agent.tool_use.params.max_iterations.label": "Maksymalna liczba iteracji",
    "modules.agent.tool_use.params.model.description": "Model do użycia",
    "modules.agent.tool_use.params.model.label": "Model",
    "modules.agent.tool_use.params.prompt.description": "Cel lub zadanie dla agenta",
    "modules.agent.tool_use.params.prompt.label": "Zadanie",
    "modules.agent.tool_use.params.provider.description": "Dostawca LLM dla agenta",
    "modules.agent.tool_use.params.provider.label": "Dostawca",
    "modules.agent.tool_use.params.system_prompt.description": "Opcjonalna systemowa podpowiedź do kierowania agentem",
    "modules.agent.tool_use.params.system_prompt.label": "Podpowiedź Systemowa",
    "modules.agent.tool_use.params.tools.description": "Lista definicji narzędzi [{name, description, parameters}]",
    "modules.agent.tool_use.params.tools.label": "Narzędzia"
  }
}
