{
  "$schema": "../../schema/locale.schema.json",
  "locale": "pl",
  "category": "llm",
  "version": "1.0.0",
  "translations": {
    "modules.llm.agent.description": "Autonomiczny agent AI z wieloportowymi polaczeniami (model, pamiec, narzedzia)",
    "modules.llm.agent.label": "Agent AI",
    "modules.llm.agent.output.ok.description": "Czy agent zakonczyl pomyslnie",
    "modules.llm.agent.output.result.description": "Czy agent zakonczyl pomyslnie",
    "modules.llm.agent.output.steps.description": "Czy agent zakonczyl pomyslnie",
    "modules.llm.agent.output.tokens_used.description": "Lista krokow wykonanych przez agenta",
    "modules.llm.agent.output.tool_calls.description": "Koncowy wynik od agenta",
    "modules.llm.agent.params.context": "Dostepne narzedzia",
    "modules.llm.agent.params.context.description": "Lista ID modulow (alternatywa dla laczenia wezlow narzedzi)",
    "modules.llm.agent.params.join_separator": "Separator laczenia",
    "modules.llm.agent.params.join_separator.description": "Separator do laczenia elementow tablicy",
    "modules.llm.agent.params.join_strategy": "Strategia laczenia tablic",
    "modules.llm.agent.params.join_strategy.description": "Jak obslugiwac dane wejsciowe tablicy",
    "modules.llm.agent.params.max_input_size": "Maks. rozmiar wejscia",
    "modules.llm.agent.params.max_input_size.description": "Maksymalna liczba znakow dla promptu (zapobiega przepelnieniu)",
    "modules.llm.agent.params.max_iterations": "Kontekst",
    "modules.llm.agent.params.max_iterations.description": "Dodatkowe dane kontekstowe dla agenta",
    "modules.llm.agent.params.prompt_path": "Sciezka promptu",
    "modules.llm.agent.params.prompt_path.description": "Sciezka do wyodrebnienia promptu z wejscia (np. {{input.message}})",
    "modules.llm.agent.params.prompt_source": "Zrodlo promptu",
    "modules.llm.agent.params.prompt_source.description": "Skad pobrac prompt zadania",
    "modules.llm.agent.params.system_prompt": "Prompt systemowy",
    "modules.llm.agent.params.system_prompt.description": "Instrukcje dla zachowania agenta",
    "modules.llm.agent.params.task": "Zadanie",
    "modules.llm.agent.params.task.description": "Zadanie do wykonania przez agenta. Uzyj {{input}} aby odwolac sie do danych upstream.",
    "modules.llm.agent.params.tools": "Dostepne narzedzia",
    "modules.llm.agent.params.tools.description": "Lista ID modulow (alternatywa dla laczenia wezlow narzedzi)",
    "modules.llm.agent.ports.input": "Wejscie",
    "modules.llm.agent.ports.memory": "Model",
    "modules.llm.agent.ports.model": "Wejscie",
    "modules.llm.agent.ports.output": "Narzedzia",
    "modules.llm.agent.ports.tools": "Pamiec",
    "modules.llm.chat.description": "Interakcja z API LLM dla inteligentnych operacji",
    "modules.llm.chat.label": "Czat LLM",
    "modules.llm.chat.output.finish_reason.description": "Uzyty model",
    "modules.llm.chat.output.model.description": "Tekst odpowiedzi LLM",
    "modules.llm.chat.output.ok.description": "Czy zadanie sie powiodlo",
    "modules.llm.chat.output.parsed.description": "Czy zadanie sie powiodlo",
    "modules.llm.chat.output.response.description": "Czy zadanie sie powiodlo",
    "modules.llm.chat.output.tokens_used.description": "Sparsowana odpowiedz (jesli zadano formatu JSON)",
    "modules.llm.code_fix.description": "Automatycznie generuj poprawki kodu na podstawie problemow",
    "modules.llm.code_fix.label": "Naprawa kodu AI",
    "modules.llm.code_fix.output.applied.description": "Czy operacja sie powiodla",
    "modules.llm.code_fix.output.failed.description": "Lista wygenerowanych poprawek",
    "modules.llm.code_fix.output.fixes.description": "Czy operacja sie powiodla",
    "modules.llm.code_fix.output.ok.description": "Czy operacja sie powiodla",
    "modules.llm.code_fix.output.summary.description": "Lista zastosowanych poprawek (jesli fix_mode to apply)"
  }
}
